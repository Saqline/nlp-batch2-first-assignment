{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Why is it important to remove stop words in text preprocessing? How can you do it in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Stop words are common words that add little value to text analysis and can be removed to improve model performance.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [word for word in text.split() if word.lower() not in stop_words]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.How can you remove numeric values from a text in Python? Provide an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text = \"The year is 2024 and the price is $50.\"\n",
    "cleaned_text = re.sub(r'\\d+', '', text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.What is the purpose of normalization in text preprocessing? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization standardizes text data to a consistent format, improving model performance.\n",
    "\n",
    "text = \"The U.S.A. is the USA.\"\n",
    "normalized_text = text.lower().replace(\"u.s.a.\", \"usa\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
